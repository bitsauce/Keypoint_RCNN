{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN for Keypoint Detection\n",
    "\n",
    "Example showing how to do keypoint detection with Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "USE_GPU    = True\n",
    "MODEL_NAME = \"run2\"\n",
    "\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "if not USE_GPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug\n",
    "import time\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\", MODEL_NAME)\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load COCO Datasets for Keypoint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use images in /datasets/home/78/378/cs252cas/Pose_RCNN/data/coco/train2017\n",
      "Will use annotations in /datasets/home/78/378/cs252cas/Pose_RCNN/data/coco/annotations/person_keypoints_train2017.json\n",
      "loading annotations into memory...\n",
      "Done (t=9.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Will use images in /datasets/home/78/378/cs252cas/Pose_RCNN/data/coco/val2017\n",
      "Will use annotations in /datasets/home/78/378/cs252cas/Pose_RCNN/data/coco/annotations/person_keypoints_val2017.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from coco import coco_keypoints\n",
    "importlib.reload(coco_keypoints)\n",
    "\n",
    "# COCO dataset dir\n",
    "COCO_DATA_DIR = \"A:/Programming/DeepLearningDatasets/coco\" if os.path.isdir(\"A:/Programming/DeepLearningDatasets/coco\") else os.path.join(ROOT_DIR, \"data/coco\")\n",
    "\n",
    "# Prepare dataset\n",
    "dataset_train = coco_keypoints.CocoDataset()\n",
    "dataset_train.load_coco(COCO_DATA_DIR, subset=\"train\", year=\"2017\", auto_download=True)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = coco_keypoints.CocoDataset()\n",
    "dataset_val.load_coco(COCO_DATA_DIR, subset=\"val\", year=\"2017\", auto_download=True)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0, 'mrcnn_kp_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco_keypoints\n",
      "NUM_CLASSES                    2\n",
      "NUM_KEYPOINTS                  17\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.5\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           512\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TrainConfig(Config):\n",
    "    NAME = \"coco_keypoints\"\n",
    "    \n",
    "    # Batch size\n",
    "    IMAGES_PER_GPU = 2\n",
    "    GPU_COUNT = 1\n",
    "    #MAX_GT_INSTANCES = 1\n",
    "    \n",
    "    # We use resnet50\n",
    "    BACKBONE = \"resnet50\"\n",
    "    \n",
    "    # Set number of classes\n",
    "    NUM_CLASSES   = dataset_train.num_classes\n",
    "    NUM_KEYPOINTS = dataset_train.num_kp_classes\n",
    "    \n",
    "    # DEBUG:\n",
    "    STEPS_PER_EPOCH  = 1000 if USE_GPU else 10\n",
    "    VALIDATION_STEPS = 50 if USE_GPU else 5\n",
    "    \n",
    "    TRAIN_ROIS_PER_IMAGE = 512\n",
    "    \n",
    "    RPN_NMS_THRESHOLD = 0.5\n",
    "    \n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "\n",
    "config = TrainConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "gt_kp_masks.shape (?, 17)\n",
      "kp_masks.shape (?, 17)\n",
      "kps_1d_indices.shape (?,)\n",
      "kps_x.shape (?, ?)\n",
      "kps_x.shape (?, ?)\n",
      "kps_x.shape (?, ?)\n",
      "masks.shape (?, 28, 28)\n",
      "gt_kp_masks.shape (?, 17)\n",
      "kp_masks.shape (?, 17)\n",
      "kps_1d_indices.shape (?,)\n",
      "kps_x.shape (?, ?)\n",
      "kps_x.shape (?, ?)\n",
      "kps_x.shape (?, ?)\n",
      "masks.shape (?, 28, 28)\n",
      "mrcnn_kp_masks.shape (?, 512, 17, 28, 28)\n",
      "Loading weights from  /datasets/home/78/378/cs252cas/Pose_RCNN/logs/run_1/coco_keypoints20180606T2342/mask_rcnn_coco_keypoints_0012.h5\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    importlib.reload(modellib)\n",
    "\n",
    "    # Create model\n",
    "    print(\"Creating model...\")\n",
    "    model = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "    # Get path to saved weights\n",
    "    try:\n",
    "        model_path = model.find_last()[1]\n",
    "        if model_path is None: raise Exception(\"\")\n",
    "            \n",
    "        # Load trained weights\n",
    "        print(\"Loading weights from \", model_path)\n",
    "        model.load_weights(model_path, by_name=True)\n",
    "    except:\n",
    "        # Load weights trained on MS-COCO\n",
    "        print(\"Loading weights pretrained on MS-COCO\")\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads...\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /datasets/home/78/378/cs252cas/Pose_RCNN/logs/run_1/coco_keypoints20180606T2342/mask_rcnn_coco_keypoints_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_kp_mask_conv0    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn0      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv1    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn1      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv2    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn2      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv3    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn3      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv4    (TimeDistributed)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn4      (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_kp_mask_conv5    (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn5      (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv6    (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn6      (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv7    (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn7      (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_kp_mask_deconv   (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask_channel_last   (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 999/1000 [============================>.] - ETA: 1s - loss: 7.6344 - rpn_class_loss: 0.0450 - rpn_bbox_loss: 0.6008 - mrcnn_class_loss: 0.0119 - mrcnn_bbox_loss: 0.4346 - mrcnn_mask_loss: 0.3921 - mrcnn_kp_mask_loss: 6.1501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1360s 1s/step - loss: 7.6340 - rpn_class_loss: 0.0450 - rpn_bbox_loss: 0.6006 - mrcnn_class_loss: 0.0119 - mrcnn_bbox_loss: 0.4348 - mrcnn_mask_loss: 0.3920 - mrcnn_kp_mask_loss: 6.1497 - val_loss: 7.1250 - val_rpn_class_loss: 0.0339 - val_rpn_bbox_loss: 0.5319 - val_mrcnn_class_loss: 0.0094 - val_mrcnn_bbox_loss: 0.3700 - val_mrcnn_mask_loss: 0.3724 - val_mrcnn_kp_mask_loss: 5.8074\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1348s 1s/step - loss: 6.9487 - rpn_class_loss: 0.0423 - rpn_bbox_loss: 0.5566 - mrcnn_class_loss: 0.0102 - mrcnn_bbox_loss: 0.3699 - mrcnn_mask_loss: 0.3736 - mrcnn_kp_mask_loss: 5.5961 - val_loss: 6.6466 - val_rpn_class_loss: 0.0343 - val_rpn_bbox_loss: 0.4660 - val_mrcnn_class_loss: 0.0089 - val_mrcnn_bbox_loss: 0.3637 - val_mrcnn_mask_loss: 0.3703 - val_mrcnn_kp_mask_loss: 5.4034\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1365s 1s/step - loss: 6.6446 - rpn_class_loss: 0.0381 - rpn_bbox_loss: 0.5513 - mrcnn_class_loss: 0.0094 - mrcnn_bbox_loss: 0.3495 - mrcnn_mask_loss: 0.3626 - mrcnn_kp_mask_loss: 5.3336 - val_loss: 6.4755 - val_rpn_class_loss: 0.0362 - val_rpn_bbox_loss: 0.4861 - val_mrcnn_class_loss: 0.0094 - val_mrcnn_bbox_loss: 0.3356 - val_mrcnn_mask_loss: 0.3548 - val_mrcnn_kp_mask_loss: 5.2534\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1357s 1s/step - loss: 6.4321 - rpn_class_loss: 0.0362 - rpn_bbox_loss: 0.5130 - mrcnn_class_loss: 0.0088 - mrcnn_bbox_loss: 0.3416 - mrcnn_mask_loss: 0.3609 - mrcnn_kp_mask_loss: 5.1715 - val_loss: 6.3050 - val_rpn_class_loss: 0.0335 - val_rpn_bbox_loss: 0.4307 - val_mrcnn_class_loss: 0.0108 - val_mrcnn_bbox_loss: 0.3243 - val_mrcnn_mask_loss: 0.3543 - val_mrcnn_kp_mask_loss: 5.1515\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1363s 1s/step - loss: 6.3343 - rpn_class_loss: 0.0363 - rpn_bbox_loss: 0.5244 - mrcnn_class_loss: 0.0088 - mrcnn_bbox_loss: 0.3372 - mrcnn_mask_loss: 0.3573 - mrcnn_kp_mask_loss: 5.0703 - val_loss: 6.1271 - val_rpn_class_loss: 0.0318 - val_rpn_bbox_loss: 0.4052 - val_mrcnn_class_loss: 0.0087 - val_mrcnn_bbox_loss: 0.3098 - val_mrcnn_mask_loss: 0.3672 - val_mrcnn_kp_mask_loss: 5.0044\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1361s 1s/step - loss: 6.2297 - rpn_class_loss: 0.0357 - rpn_bbox_loss: 0.5211 - mrcnn_class_loss: 0.0088 - mrcnn_bbox_loss: 0.3329 - mrcnn_mask_loss: 0.3575 - mrcnn_kp_mask_loss: 4.9738 - val_loss: 6.2442 - val_rpn_class_loss: 0.0312 - val_rpn_bbox_loss: 0.4217 - val_mrcnn_class_loss: 0.0078 - val_mrcnn_bbox_loss: 0.3172 - val_mrcnn_mask_loss: 0.3589 - val_mrcnn_kp_mask_loss: 5.1074\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1364s 1s/step - loss: 6.1244 - rpn_class_loss: 0.0344 - rpn_bbox_loss: 0.5375 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.3257 - mrcnn_mask_loss: 0.3528 - mrcnn_kp_mask_loss: 4.8654 - val_loss: 6.0301 - val_rpn_class_loss: 0.0342 - val_rpn_bbox_loss: 0.4635 - val_mrcnn_class_loss: 0.0084 - val_mrcnn_bbox_loss: 0.3166 - val_mrcnn_mask_loss: 0.3277 - val_mrcnn_kp_mask_loss: 4.8796\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1379s 1s/step - loss: 6.0649 - rpn_class_loss: 0.0336 - rpn_bbox_loss: 0.4919 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.3199 - mrcnn_mask_loss: 0.3537 - mrcnn_kp_mask_loss: 4.8572 - val_loss: 6.0561 - val_rpn_class_loss: 0.0291 - val_rpn_bbox_loss: 0.5285 - val_mrcnn_class_loss: 0.0077 - val_mrcnn_bbox_loss: 0.3397 - val_mrcnn_mask_loss: 0.3567 - val_mrcnn_kp_mask_loss: 4.7943\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1378s 1s/step - loss: 6.0118 - rpn_class_loss: 0.0350 - rpn_bbox_loss: 0.4977 - mrcnn_class_loss: 0.0085 - mrcnn_bbox_loss: 0.3179 - mrcnn_mask_loss: 0.3549 - mrcnn_kp_mask_loss: 4.7979 - val_loss: 6.2266 - val_rpn_class_loss: 0.0329 - val_rpn_bbox_loss: 0.5630 - val_mrcnn_class_loss: 0.0075 - val_mrcnn_bbox_loss: 0.3326 - val_mrcnn_mask_loss: 0.3634 - val_mrcnn_kp_mask_loss: 4.9272\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1393s 1s/step - loss: 5.8861 - rpn_class_loss: 0.0316 - rpn_bbox_loss: 0.4738 - mrcnn_class_loss: 0.0078 - mrcnn_bbox_loss: 0.3118 - mrcnn_mask_loss: 0.3483 - mrcnn_kp_mask_loss: 4.7129 - val_loss: 5.9532 - val_rpn_class_loss: 0.0292 - val_rpn_bbox_loss: 0.4374 - val_mrcnn_class_loss: 0.0059 - val_mrcnn_bbox_loss: 0.3315 - val_mrcnn_mask_loss: 0.3501 - val_mrcnn_kp_mask_loss: 4.7991\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    importlib.reload(modellib)\n",
    "    \n",
    "    train_start_time = time.time()\n",
    "    \n",
    "    # Training - Stage 1\n",
    "    print(\"Training network heads...\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                layers=\"heads\",\n",
    "                augmentation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune Resnet stage 4 and up...\n",
      "\n",
      "Starting at epoch 10. LR=0.001\n",
      "\n",
      "Checkpoint Path: /datasets/home/78/378/cs252cas/Pose_RCNN/logs/run_1/coco_keypoints20180606T2342/mask_rcnn_coco_keypoints_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_kp_mask_conv0    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn0      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv1    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn1      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv2    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn2      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv3    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn3      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv4    (TimeDistributed)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn4      (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_kp_mask_conv5    (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn5      (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv6    (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn6      (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv7    (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn7      (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_kp_mask_deconv   (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask_channel_last   (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    importlib.reload(modellib)\n",
    "\n",
    "    # Training - Stage 2\n",
    "    # Finetune layers from ResNet stage 4 and up\n",
    "    print(\"Fine tune Resnet stage 4 and up...\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                layers=\"4+\",\n",
    "                augmentation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tune all layers...\n",
      "\n",
      "Starting at epoch 12. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /datasets/home/78/378/cs252cas/Pose_RCNN/logs/run_1/coco_keypoints20180606T2342/mask_rcnn_coco_keypoints_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_kp_mask_conv0    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn0      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv1    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn1      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv2    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn2      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv3    (TimeDistributed)\n",
      "mrcnn_kp_mask_bn3      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv4    (TimeDistributed)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn4      (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_kp_mask_conv5    (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn5      (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv6    (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn6      (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_kp_mask_conv7    (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_kp_mask_bn7      (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_kp_mask_deconv   (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask_channel_last   (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      " 999/1000 [============================>.] - ETA: 1s - loss: 5.7335 - rpn_class_loss: 0.0323 - rpn_bbox_loss: 0.4723 - mrcnn_class_loss: 0.0080 - mrcnn_bbox_loss: 0.3007 - mrcnn_mask_loss: 0.3393 - mrcnn_kp_mask_loss: 4.5808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1430s 1s/step - loss: 5.7326 - rpn_class_loss: 0.0322 - rpn_bbox_loss: 0.4720 - mrcnn_class_loss: 0.0080 - mrcnn_bbox_loss: 0.3005 - mrcnn_mask_loss: 0.3391 - mrcnn_kp_mask_loss: 4.5806 - val_loss: 5.8549 - val_rpn_class_loss: 0.0309 - val_rpn_bbox_loss: 0.4352 - val_mrcnn_class_loss: 0.0085 - val_mrcnn_bbox_loss: 0.3137 - val_mrcnn_mask_loss: 0.3375 - val_mrcnn_kp_mask_loss: 4.7291\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 1448s 1s/step - loss: 5.7510 - rpn_class_loss: 0.0322 - rpn_bbox_loss: 0.4693 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 0.3006 - mrcnn_mask_loss: 0.3401 - mrcnn_kp_mask_loss: 4.6005 - val_loss: 5.8035 - val_rpn_class_loss: 0.0272 - val_rpn_bbox_loss: 0.3643 - val_mrcnn_class_loss: 0.0086 - val_mrcnn_bbox_loss: 0.3090 - val_mrcnn_mask_loss: 0.3566 - val_mrcnn_kp_mask_loss: 4.7378\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 1395s 1s/step - loss: 5.6580 - rpn_class_loss: 0.0298 - rpn_bbox_loss: 0.4455 - mrcnn_class_loss: 0.0074 - mrcnn_bbox_loss: 0.2948 - mrcnn_mask_loss: 0.3365 - mrcnn_kp_mask_loss: 4.5440 - val_loss: 5.6571 - val_rpn_class_loss: 0.0282 - val_rpn_bbox_loss: 0.3835 - val_mrcnn_class_loss: 0.0086 - val_mrcnn_bbox_loss: 0.3022 - val_mrcnn_mask_loss: 0.3197 - val_mrcnn_kp_mask_loss: 4.6148\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 1363s 1s/step - loss: 5.7268 - rpn_class_loss: 0.0319 - rpn_bbox_loss: 0.4547 - mrcnn_class_loss: 0.0078 - mrcnn_bbox_loss: 0.3036 - mrcnn_mask_loss: 0.3436 - mrcnn_kp_mask_loss: 4.5852 - val_loss: 5.8736 - val_rpn_class_loss: 0.0349 - val_rpn_bbox_loss: 0.3864 - val_mrcnn_class_loss: 0.0089 - val_mrcnn_bbox_loss: 0.3249 - val_mrcnn_mask_loss: 0.3771 - val_mrcnn_kp_mask_loss: 4.7414\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 1370s 1s/step - loss: 5.6634 - rpn_class_loss: 0.0295 - rpn_bbox_loss: 0.4576 - mrcnn_class_loss: 0.0073 - mrcnn_bbox_loss: 0.2938 - mrcnn_mask_loss: 0.3351 - mrcnn_kp_mask_loss: 4.5402 - val_loss: 5.7316 - val_rpn_class_loss: 0.0275 - val_rpn_bbox_loss: 0.4008 - val_mrcnn_class_loss: 0.0090 - val_mrcnn_bbox_loss: 0.2898 - val_mrcnn_mask_loss: 0.3378 - val_mrcnn_kp_mask_loss: 4.6669\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 1379s 1s/step - loss: 5.6781 - rpn_class_loss: 0.0297 - rpn_bbox_loss: 0.4517 - mrcnn_class_loss: 0.0074 - mrcnn_bbox_loss: 0.2942 - mrcnn_mask_loss: 0.3400 - mrcnn_kp_mask_loss: 4.5550 - val_loss: 5.8153 - val_rpn_class_loss: 0.0343 - val_rpn_bbox_loss: 0.3559 - val_mrcnn_class_loss: 0.0106 - val_mrcnn_bbox_loss: 0.3353 - val_mrcnn_mask_loss: 0.3430 - val_mrcnn_kp_mask_loss: 4.7362\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 1382s 1s/step - loss: 5.6620 - rpn_class_loss: 0.0293 - rpn_bbox_loss: 0.4449 - mrcnn_class_loss: 0.0071 - mrcnn_bbox_loss: 0.2923 - mrcnn_mask_loss: 0.3386 - mrcnn_kp_mask_loss: 4.5498 - val_loss: 5.9441 - val_rpn_class_loss: 0.0275 - val_rpn_bbox_loss: 0.4521 - val_mrcnn_class_loss: 0.0067 - val_mrcnn_bbox_loss: 0.3060 - val_mrcnn_mask_loss: 0.3544 - val_mrcnn_kp_mask_loss: 4.7975\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 1458s 1s/step - loss: 5.6608 - rpn_class_loss: 0.0290 - rpn_bbox_loss: 0.4507 - mrcnn_class_loss: 0.0070 - mrcnn_bbox_loss: 0.2969 - mrcnn_mask_loss: 0.3366 - mrcnn_kp_mask_loss: 4.5405 - val_loss: 5.5389 - val_rpn_class_loss: 0.0257 - val_rpn_bbox_loss: 0.4372 - val_mrcnn_class_loss: 0.0060 - val_mrcnn_bbox_loss: 0.2780 - val_mrcnn_mask_loss: 0.3252 - val_mrcnn_kp_mask_loss: 4.4668\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    importlib.reload(modellib)\n",
    "\n",
    "    # Training - Stage 3\n",
    "    # Fine tune all layers\n",
    "    print(\"Fine tune all layers...\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE / 10,\n",
    "                epochs=20,\n",
    "                layers=\"all\",\n",
    "                augmentation=None)\n",
    "    \n",
    "    # Training done\n",
    "    print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of losses:\n",
    "\n",
    "- rpn_class_loss: \"How well does the network separate positive from negative anchors?\"\n",
    "- rpn_bbox_loss: \"How accurate are proposed the bounding boxes?\"\n",
    "- mrcnn_class_loss: \"How well does the network distinguish people from background RoIs?\" (really, this is the same as 1.)\n",
    "- mrcnn_bbox_loss: \"Bounding box refinement loss\" (is this the same as 2.?)\n",
    "- mrcnn_mask_loss: \"How accurate are the predicted keypoints?\" (per mask softmax cross-entropy loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
